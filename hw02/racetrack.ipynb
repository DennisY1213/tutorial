{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "674c9ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "# sys.path.append('~/Desktop/Tufts-CS/CS138/hw02')\n",
    "from track import build_track\n",
    "from agent import Agent\n",
    "from environment import Environment\n",
    "# Constants\n",
    "GRID_SIZE = 32\n",
    "CELL_SIZE = 20\n",
    "FPS = 60\n",
    "GRID_WIDTH = GRID_SIZE * CELL_SIZE\n",
    "GRID_HEIGHT = GRID_SIZE * CELL_SIZE\n",
    "BLACK = (0, 0, 0)\n",
    "WHITE = (255, 255, 255)\n",
    "TRACK_COLOR = (120, 120, 120)\n",
    "GRAVEL_COLOR = (255, 255, 255)\n",
    "FIN_COLOR = (255, 0, 0)\n",
    "START_COLOR = (0, 255, 0)\n",
    "CAR_COLOR = (0, 0, 255)\n",
    "GRAVEL = -1\n",
    "TRACK = 0\n",
    "START = 1\n",
    "FINISH = 2\n",
    "num_action = 9\n",
    "# ##build the track\n",
    "track = build_track()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "81fcc081",
   "metadata": {},
   "outputs": [],
   "source": [
    "##train on-policy\n",
    "race_track = Environment(track)\n",
    "epsilons = [0.1,0.15,0.2,0.25]\n",
    "res = []\n",
    "for e in epsilons:\n",
    "    agent1 = Agent(epsilon = e)\n",
    "    episode_len1 = agent1.mc_control(race_track, 1000, on_policy=True)\n",
    "    res.append(episode_len1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "79e2f228",
   "metadata": {},
   "outputs": [],
   "source": [
    "##train off-policy\n",
    "race_track = Environment(track)\n",
    "epsilons = [0.1,0.15,0.2,0.25]\n",
    "res1 = []\n",
    "# for e in epsilons:\n",
    "#     agent1 = Agent(epsilon = e)\n",
    "#     episode_len1 = agent1.mc_control(race_track, 1000, on_policy=False)\n",
    "#     res1.append(episode_len1)\n",
    "episode_len1 = agent1.mc_control(race_track, 1000, on_policy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e6c9e470",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,10))\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "palette = plt.get_cmap('Set1')\n",
    "for i in range(len(gammas)):\n",
    "    plt.semilogx(np.arange(1000), res[i], color=palette(i+1), linewidth=2.5, alpha=0.9, label=f'on-policy MC control (epsilon={epsilons[i]})')\n",
    "plt.ylim(0, 3000)\n",
    "plt.xlabel('Episode', fontsize=16)\n",
    "plt.ylabel('Episode Length', fontsize=16)\n",
    "plt.title('Episode Lengths over Episodes', fontsize=18)\n",
    "\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.legend(fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.savefig(\"op_t2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d9a29277",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,10))\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "palette = plt.get_cmap('Set1')\n",
    "plt.semilogx(np.arange(1000), res1[0], color=palette(2), linewidth=1.5, alpha=0.9, label='off-policy MC control(epsilon=0.1)')\n",
    "plt.semilogx(np.arange(1000), res[0], color=palette(3), linewidth=1.5, alpha=0.9, label='on-policy MC control(epsilon=0.1)')\n",
    "\n",
    "plt.ylim(0, 3000)\n",
    "plt.xlabel('Episode', fontsize=16)\n",
    "plt.ylabel('Episode Length', fontsize=16)\n",
    "plt.title('Episode Lengths over Episodes', fontsize=18)\n",
    "\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.legend(fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.savefig(\"op_t3.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f837a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##To visualize the tragectory\n",
    "def draw_grid(screen,grid, path):\n",
    "        for y in range(GRID_SIZE):\n",
    "            for x in range(GRID_SIZE):\n",
    "                if grid[x][y] == START:\n",
    "                    color = START_COLOR\n",
    "                    pygame.draw.rect(screen, START_COLOR, (y * CELL_SIZE, x * CELL_SIZE, CELL_SIZE, CELL_SIZE), 0)\n",
    "\n",
    "                elif grid[x][y] == FINISH:\n",
    "                    color = FIN_COLOR\n",
    "                    pygame.draw.rect(screen, FIN_COLOR, (y * CELL_SIZE, x * CELL_SIZE, CELL_SIZE, CELL_SIZE), 0)\n",
    "\n",
    "                if grid[x][y] == TRACK:\n",
    "                    color = TRACK_COLOR\n",
    "                elif grid[x][y] == GRAVEL:\n",
    "                    color = GRAVEL_COLOR\n",
    "                pygame.draw.rect(screen, color, (y * CELL_SIZE, x * CELL_SIZE, CELL_SIZE, CELL_SIZE), 1)\n",
    "        \n",
    "        #Draw the car\n",
    "        for state in path:\n",
    "            pygame.draw.rect(screen, CAR_COLOR, (state[1] * CELL_SIZE, state[0] * CELL_SIZE, CELL_SIZE, CELL_SIZE), 0)\n",
    "\n",
    "def display(track,path, index):   \n",
    "    # Initialize Pygame\n",
    "    pygame.init()      \n",
    "    # Create a Pygame window\n",
    "    screen = pygame.display.set_mode((GRID_WIDTH, GRID_HEIGHT))\n",
    "    pygame.display.set_caption(\"Race Track\")       \n",
    "    clock = pygame.time.Clock()\n",
    "    screen.fill(WHITE)\n",
    "\n",
    "    running = True\n",
    "    while running:\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                running = False\n",
    "\n",
    "        screen.fill(WHITE)  # Clear the screen\n",
    "        draw_grid(screen, track, path)     # Draw the grid\n",
    "        pygame.display.flip()\n",
    "        running = False\n",
    "        screenshot_dir = \"screenshots\"  # Directory to save screenshots\n",
    "        screenshot_name = f\"screenshot{index}.png\"  # Name of the screenshot file\n",
    "\n",
    "        # Create the screenshots directory if it doesn't exist\n",
    "        if not os.path.exists(screenshot_dir):\n",
    "            os.makedirs(screenshot_dir)\n",
    "\n",
    "        # Capture the current frame and save it as a screenshot\n",
    "        pygame.image.save(screen, os.path.join(screenshot_dir, screenshot_name))\n",
    "        clock.tick(FPS)\n",
    "    pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8347913f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##generate off-policy tragectory\n",
    "def off_generate_tragectory(agent, env):\n",
    "    agent.state, agent.speed = env.reset()\n",
    "    episode_states = []\n",
    "    total_reward = 0\n",
    "\n",
    "    # Generate an episode using target policy\n",
    "    while True:\n",
    "        total_reward += -1\n",
    "        episode_states.append(agent.state)\n",
    "#         policy = agent.soft_policy(agent.Q[agent.state])\n",
    "        action = agent.target_policy[agent.state]\n",
    "        print(action, agent.actions[action])\n",
    "        reward, terminated, new_state, new_speed = env.take_action(agent.state, agent.speed, agent.actions[action])\n",
    "        print(new_state, new_speed)\n",
    "        if new_state in env.start_set:\n",
    "            episode_states = []\n",
    "#             new_speed = [0,1]\n",
    "        agent.state = new_state\n",
    "        agent.speed = new_speed\n",
    "\n",
    "        if terminated:\n",
    "            episode_states.append(agent.state)\n",
    "            break\n",
    "    return episode_states, total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cd13c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##generate on-policy tragectory\n",
    "def on_generate_tragectory(agent, env):\n",
    "    agent.state, agent.speed = env.reset()\n",
    "    episode_states = []\n",
    "    total_r = 0\n",
    "\n",
    "    # Generate an episode using target policy\n",
    "    while True:\n",
    "        total_r += -1\n",
    "        episode_states.append(agent.state)\n",
    "        policy = agent.soft_policy(agent.Q[agent.state])\n",
    "        action = np.random.choice(np.arange(agent.num_actions), p=policy)\n",
    "        # print(action, self.actions[action])\n",
    "        reward, terminated, new_state, new_speed = env.take_action(agent.state, agent.speed, agent.actions[action])\n",
    "        if new_state in env.start_set:\n",
    "            episode_states = []\n",
    "        # env.display(self.state)                \n",
    "        agent.state = new_state\n",
    "        agent.speed = new_speed\n",
    "\n",
    "        if terminated:\n",
    "            episode_states.append(agent.state)\n",
    "            break\n",
    "    return episode_states, total_r\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8302e362",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_list = []\n",
    "for i in range(1000):\n",
    "    path, total_r = off_generate_tragectory(agent, race_track)\n",
    "    r_list.append(total_r)\n",
    "    # display(track, path, i)\n",
    "\n",
    "r_list1 = []\n",
    "for i in range(1000):\n",
    "    path, total_r = generate_tragectory(agent1, race_track)\n",
    "    r_list1.append(total_r)\n",
    "    # display(track, path, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332351e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##plot average reward for off-policy\n",
    "plt.figure(figsize = (15,10))\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "plt.plot(np.arange(1000), r_list, label = \"reward of each episode\")\n",
    "plt.plot(np.arange(1000), [np.mean(r_list)] * 1000, linewidth=2.5, alpha=0.9, label = \"mean rewards\")\n",
    "plt.xlabel('Episode', fontsize=16)\n",
    "plt.ylabel('Reward of an episode', fontsize=16)\n",
    "plt.title('Rewards of 1000 random episodes', fontsize=15)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.legend(fontsize = 18)\n",
    "plt.grid(True)\n",
    "plt.savefig(\"screenshots/op_r.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c882ed56",
   "metadata": {},
   "outputs": [],
   "source": [
    "##plot average reward for on-policy\n",
    "plt.figure(figsize = (15,10))\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "plt.plot(np.arange(1000), r_list1, label = \"reward of each episode\")\n",
    "plt.plot(np.arange(1000), [np.mean(r_list1)] * 1000, linewidth=2.5, alpha=0.9, label = \"mean rewards\")\n",
    "plt.xlabel('Episode', fontsize=16)\n",
    "plt.ylabel('Reward of an episode', fontsize=16)\n",
    "plt.title('Rewards of 1000 random episodes', fontsize=15)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.legend(fontsize = 18)\n",
    "plt.savefig(\"screenshots/op_r1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8adff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a grid of subplots\n",
    "num_rows = 2  # Number of rows in the grid\n",
    "num_cols = 5  # Number of columns in the grid\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(8, 8))\n",
    "\n",
    "# Populate the subplots with images\n",
    "for i in range(0,num_rows,2):\n",
    "    for j in range(num_cols):\n",
    "        index = i * num_cols + j  # Calculate the index for accessing image_paths\n",
    "        # Open the image using PIL\n",
    "        img = Image.open(f'screenshots/screenshot{index}.png')\n",
    "        axes[i, j].imshow(img)\n",
    "        axes[i, j].set_title(f'Path {index//2 + 1}')\n",
    "        axes[i, j].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace= -0.5)\n",
    "\n",
    "# plt.show()\n",
    "plt.savefig('screenshots/fig1.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
